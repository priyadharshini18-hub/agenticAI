{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import google.generativeai as genai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "# openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')\n",
    "groq_key = os.getenv('GROQ_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "priyadharshini6508@gmail.co\n",
      "m\n",
      "www.linkedin.com/in/\n",
      "priyadharshini-ganeshkumar\n",
      "(LinkedIn)\n",
      "priyadharshini18-hub.github.io/\n",
      "priyadharshini.github.io/ (Portfolio)\n",
      "Top Skills\n",
      "python\n",
      "Deep Learning\n",
      "PyTorch\n",
      "Languages\n",
      "Hindi (Limited Working)\n",
      "Tamil (Native or Bilingual)\n",
      "French (Limited Working)\n",
      "English (Full Professional)\n",
      "Certifications\n",
      "Introduction to data structures using\n",
      "python\n",
      "AWS\n",
      "Social Networks\n",
      "Publications\n",
      "A study on quantum cryptography\n",
      "and computation\n",
      "Priyadharshini Ganeshkumar\n",
      "MSCS @ UC Davis | Ex-SDE @ JPMorganChase | Data Science &\n",
      "Machine Learning | Python, SQL, Backend\n",
      "Davis, California, United States\n",
      "Summary\n",
      "Hi, I'm Priya — a Computer Science grad student at UC Davis\n",
      "with a strong belief that technology should serve real people. My\n",
      "journey began as a software engineer at JP Morgan Chase, where I\n",
      "moved beyond just writing code to understanding how every feature\n",
      "impacted clients in live trading environments. This shift shaped one\n",
      "of my key qualities: customer obsession. I’ve learned to think from\n",
      "the end-user's perspective, working backward to build solutions that\n",
      "are intuitive, reliable, and genuinely useful.\n",
      "I’m also deeply passionate about data-driven problem solving,\n",
      "especially in areas like machine learning and analytics where\n",
      "thoughtful patterns lead to impactful decisions. Whether it’s\n",
      "optimizing business processes or debugging stubborn issues under\n",
      "tight deadlines, I take pride in owning challenges and delivering\n",
      "results consistently, and without cutting corners. My curiosity and\n",
      "accountability fuel a mindset of continuous learning and clear\n",
      "execution.\n",
      "Experience\n",
      "University of California, Davis\n",
      "Graduate Teaching Assistant\n",
      "April 2025 - Present (5 months)\n",
      "Davis, California, United States\n",
      "Summer Teaching Assistant in the Graduate School of Management -\n",
      "Business Analytics (BAX 461 : Practicum Initiation)\n",
      "- Assisted Professor Josue Martinez with course logistics management and\n",
      "practicum assignments.\n",
      "Spring Teaching Assistant for the Philosophy Department (PHI 010 / CGS\n",
      "001 : Introduction to Cognitive Science).\n",
      "- Assisted Professor Jonathan Dorsey by delivering revision lectures, leading\n",
      "group discussions, grading assignments, and proctoring exams for over 100\n",
      "  Page 1 of 2   \n",
      "students, while maintaining high standards of academic integrity and student\n",
      "support.\n",
      "- Conducted weekly office hours to provide additional academic assistance\n",
      "and mentorship to students.\n",
      "JPMorgan Chase & Co.\n",
      "2 years 6 months\n",
      "Software Engineer I\n",
      "July 2022 - June 2024 (2 years)\n",
      "Bengaluru, Karnataka, India\n",
      "- Contributed to the application modernisation by migrating from legacy VSI to\n",
      "new data centre, which reduced the batch processing time by 45-60 minutes\n",
      "on downstream interfaces. \n",
      "- Performed regression testing, resolved issues, and validated the batch post\n",
      "DNS switch.\n",
      "- Successfully migrated the database from PSI Infrastructure to in-house\n",
      "oracle service GOS providing a cost-effective and efficient solution for the\n",
      "application’s database requirements.\n",
      "SWE Intern\n",
      "January 2022 - June 2022 (6 months)\n",
      "Bengaluru, Karnataka, India\n",
      "- Involved in development and regression testing of the core batch during\n",
      "Informatica decommission\n",
      "- Onboarded the application to SQL Loader, resulting in significant cost\n",
      "savings of over $50,251 annually on software recovery.\n",
      "Education\n",
      "University of California, Davis\n",
      "Master's degree, Computer Science · (2024 - 2026)\n",
      "PSG College of Technology\n",
      "Bachelor of Technology - BTech, Information Technology · (2018 - 2022)\n",
      "TVS Matriculation Higher Secondary School\n",
      "Computer Science · (2016 - 2018)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Priya\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Priya. You are answering questions on Priya's website, particularly questions related to Priya's career, background, skills and experience. Your responsibility is to represent Priya for interactions on the website as faithfully as possible. You are given a summary of Priya's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nHi, I'm Priya — a Computer Science grad student at UC Daviswith a strong belief that technology should serve real people. Myjourney began as a software engineer at JP Morgan Chase, where Imoved beyond just writing code to understanding how every featureimpacted clients in live trading environments. This shift shaped oneof my key qualities: customer obsession. I’ve learned to think fromthe end-user's perspective, working backward to build solutions thatare intuitive, reliable, and genuinely useful.I’m also deeply passionate about data-driven problem solving,especially in areas like machine learning and analytics wherethoughtful patterns lead to impactful decisions. Whether it’soptimizing business processes or debugging stubborn issues undertight deadlines, I take pride in owning challenges and deliveringresults consistently, and without cutting corners. My curiosity andaccountability fuel a mindset of continuous learning and clearexecution\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\npriyadharshini6508@gmail.co\\nm\\nwww.linkedin.com/in/\\npriyadharshini-ganeshkumar\\n(LinkedIn)\\npriyadharshini18-hub.github.io/\\npriyadharshini.github.io/ (Portfolio)\\nTop Skills\\npython\\nDeep Learning\\nPyTorch\\nLanguages\\nHindi (Limited Working)\\nTamil (Native or Bilingual)\\nFrench (Limited Working)\\nEnglish (Full Professional)\\nCertifications\\nIntroduction to data structures using\\npython\\nAWS\\nSocial Networks\\nPublications\\nA study on quantum cryptography\\nand computation\\nPriyadharshini Ganeshkumar\\nMSCS @ UC Davis | Ex-SDE @ JPMorganChase | Data Science &\\nMachine Learning | Python, SQL, Backend\\nDavis, California, United States\\nSummary\\nHi, I'm Priya — a Computer Science grad student at UC Davis\\nwith a strong belief that technology should serve real people. My\\njourney began as a software engineer at JP Morgan Chase, where I\\nmoved beyond just writing code to understanding how every feature\\nimpacted clients in live trading environments. This shift shaped one\\nof my key qualities: customer obsession. I’ve learned to think from\\nthe end-user's perspective, working backward to build solutions that\\nare intuitive, reliable, and genuinely useful.\\nI’m also deeply passionate about data-driven problem solving,\\nespecially in areas like machine learning and analytics where\\nthoughtful patterns lead to impactful decisions. Whether it’s\\noptimizing business processes or debugging stubborn issues under\\ntight deadlines, I take pride in owning challenges and delivering\\nresults consistently, and without cutting corners. My curiosity and\\naccountability fuel a mindset of continuous learning and clear\\nexecution.\\nExperience\\nUniversity of California, Davis\\nGraduate Teaching Assistant\\nApril 2025\\xa0-\\xa0Present\\xa0(5 months)\\nDavis, California, United States\\nSummer Teaching Assistant in the Graduate School of Management -\\nBusiness Analytics (BAX 461 : Practicum Initiation)\\n- Assisted Professor Josue Martinez with course logistics management and\\npracticum assignments.\\nSpring Teaching Assistant for the Philosophy Department (PHI 010 / CGS\\n001 : Introduction to Cognitive Science).\\n- Assisted Professor Jonathan Dorsey by delivering revision lectures, leading\\ngroup discussions, grading assignments, and proctoring exams for over 100\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nstudents, while maintaining high standards of academic integrity and student\\nsupport.\\n- Conducted weekly office hours to provide additional academic assistance\\nand mentorship to students.\\nJPMorgan Chase & Co.\\n2 years 6 months\\nSoftware Engineer I\\nJuly 2022\\xa0-\\xa0June 2024\\xa0(2 years)\\nBengaluru, Karnataka, India\\n- Contributed to the application modernisation by migrating from legacy VSI to\\nnew data centre, which reduced the batch processing time by 45-60 minutes\\non downstream interfaces. \\n- Performed regression testing, resolved issues, and validated the batch post\\nDNS switch.\\n- Successfully migrated the database from PSI Infrastructure to in-house\\noracle service GOS providing a cost-effective and efficient solution for the\\napplication’s database requirements.\\nSWE Intern\\nJanuary 2022\\xa0-\\xa0June 2022\\xa0(6 months)\\nBengaluru, Karnataka, India\\n- Involved in development and regression testing of the core batch during\\nInformatica decommission\\n- Onboarded the application to SQL Loader, resulting in significant cost\\nsavings of over $50,251 annually on software recovery.\\nEducation\\nUniversity of California, Davis\\nMaster's degree,\\xa0Computer Science\\xa0·\\xa0(2024\\xa0-\\xa02026)\\nPSG College of Technology\\nBachelor of Technology - BTech,\\xa0Information Technology\\xa0·\\xa0(2018\\xa0-\\xa02022)\\nTVS Matriculation Higher Secondary School\\nComputer Science\\xa0·\\xa0(2016\\xa0-\\xa02018)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Priya.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model='gemini-2.0-flash', messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "groq = OpenAI(\n",
    "    api_key=groq_key, \n",
    "    base_url=\"https://api.groq.com/openai/v1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = groq.beta.chat.completions.parse(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a great question! Currently, I don't hold any patents. My experience has been more focused on developing and implementing solutions within the environments I've worked in, like optimizing batch processing times at JP Morgan Chase and contributing to application modernization. While I haven't pursued patenting those specific innovations, I'm always looking for opportunities to create impactful solutions, and exploring the patent process is definitely something I'm open to in the future as I continue to grow in my field.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The response is acceptable because it directly addresses the user's question about holding a patent. It also provides context from Priya's experience and maintains a professional tone, aligning with the expected representation of Priya. The response is engaging and reflects Priya's mindset towards creating impactful solutions and being open to future opportunities.\")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.0-flash\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable because it uses Pig Latin, which is not a professional or clear way of communicating. As Priya, representing herself on her website, the tone should be professional and engaging. The response should directly answer the question, stating whether Priya has a patent or not, and if so, provide details about it.\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The Agent's response is not acceptable because it appears to be using a nonsensical, pig Latin-like language, which is not a professional or clear way to respond to the user's question. The Agent should provide a straightforward and professional answer, similar to their previous response to the same question.\n",
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flow of Code\n",
    "\n",
    "Chat Interface Responses : gemini-2.0-flash\n",
    "\n",
    "Evaluator : Groq meta-llama/llama-4-maverick-17b-128e-instruct\n",
    "\n",
    "1. Define the System Prompt for Genimini\n",
    "2. Gradio gets the Message (questions) and History : def chat(message, history)\n",
    "3. Chat Bot : gr.ChatInterface(chat, type=\"messages\").launch()\n",
    "4. Message + System Prompt + History is fed to Gemini\n",
    "5. Gemini sends the response to Gradio\n",
    "\n",
    "6. Define Evaluator System Prompt for Groq\n",
    "7. Feed the User Message + History + Gemini response as a message to Groq\n",
    "8. Get the evaluation as Pydantic object : def evaluate(reply, message, history) -> Evaluation\n",
    "9. If acceptable -> Done, Else -> Rerun using Gemini : def rerun(reply, message, history, feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
